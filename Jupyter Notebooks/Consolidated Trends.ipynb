{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "702b38e5",
   "metadata": {},
   "source": [
    "An earlier version of the code used to filter out the Sun, the Moon, and cloudy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7c4902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- IMPORTS ---- #\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import ephem\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "# ---- CONFIG ---- #\n",
    "\n",
    "# --- Main Settings --- #\n",
    "# Choose the location to analyze from the dictionary below.\n",
    "SELECTED_LOCATION = \"Boerakker\"\n",
    "\n",
    "# Root directory where location folders (containing .dat files) are stored.\n",
    "# Example: \"C:/Users/YourUser/Desktop/SQM_Data/\"\n",
    "DATA_ROOT_DIR = r\"C:\\Users\\YourUser\\Desktop\\SQM Data\\\\\"\n",
    "\n",
    "# Path to the CSV file containing cloudiness data.\n",
    "# Source: EUMETSAT\n",
    "CLOUD_DATA_FILE = f'{SELECTED_LOCATION} cloudy or not.csv'\n",
    "\n",
    "# --- Analysis Parameters --- #\n",
    "# Hours of the night to include in the weekly analysis.\n",
    "HOURS_TO_INCLUDE = [21, 22, 23, 0, 1, 2]\n",
    "\n",
    "# --- Celestial Filter Settings --- #\n",
    "# These values determine when the sky is considered \"dark enough\".\n",
    "SUN_ALTITUDE_THRESHOLD = -18  # Degrees (Astronomical Twilight)\n",
    "MIN_DATAPOINTS_PER_FILE = 30 # Minimum readings required in a .dat file to be considered valid.\n",
    "\n",
    "# --- Location Coordinates --- #\n",
    "# Add other locations here if needed.\n",
    "LOCATIONS_DICT = {\n",
    "    \"Ameland-Natuurcentrum-Nes\": {\"lat\": \"53.449\", \"lon\": \"5.775\"},\n",
    "    \"Boerakker\": {\"lat\": \"53.187\", \"lon\": \"6.329\"},\n",
    "    \"Ostland\": {\"lat\": \"53.607\", \"lon\": \"6.727\"},\n",
    "    # ... add other locations\n",
    "}\n",
    "\n",
    "# ---- FUNCTIONS ---- #\n",
    "\n",
    "def load_cloud_data(filepath):\n",
    "    \"\"\"\n",
    "    Loads cloudiness data and returns a set of cloudy datetimes to exclude.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): The path to the 'cloudy or not.csv' file.\n",
    "\n",
    "    Returns:\n",
    "        set: A set of 'YYYY-MM-DD HH' strings for periods identified as cloudy.\n",
    "    \"\"\"\n",
    "    print(f\"Loading cloud data from: {filepath}\")\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Cloud data file not found at {filepath}. No data will be excluded for cloudiness.\")\n",
    "        return set()\n",
    "\n",
    "    # Extract date/time components from the filename column\n",
    "    df['year'] = df['filename'].str.slice(28, 32)\n",
    "    df['month'] = df['filename'].str.slice(32, 34)\n",
    "    df['day'] = df['filename'].str.slice(34, 36)\n",
    "    df['hour'] = df['filename'].str.slice(36, 38) # Keep as string for formatting\n",
    "\n",
    "    # Create a 'YYYY-MM-DD HH' string to match the main DataFrame\n",
    "    df['datetime_hour_str'] = df['year'] + '-' + df['month'] + '-' + df['day'] + ' ' + df['hour']\n",
    "\n",
    "    # Filter for cloudy conditions and return the set of cloudy hour strings\n",
    "    cloudy_hours = set(df[df['datavals'] == 'Cloudy']['datetime_hour_str'])\n",
    "    print(f\"Found {len(cloudy_hours)} cloudy hours to exclude.\")\n",
    "    return cloudy_hours\n",
    "\n",
    "\n",
    "def calculate_celestial_altitudes(row, observer):\n",
    "    \"\"\"\n",
    "    Calculates the sun/moon altitude and moon phase for a given timestamp.\n",
    "    \n",
    "    Args:\n",
    "        row (pd.Series): A row from a DataFrame with datetime information.\n",
    "        observer (ephem.Observer): An ephem Observer object configured with lat/lon.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing (sun_alt_deg, moon_alt_deg, moon_phase_percent).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Expects a datetime object in the 'Datetime' column\n",
    "        observer.date = row[\"Datetime\"]\n",
    "    except (ValueError, TypeError):\n",
    "        return None, None, None\n",
    "\n",
    "    sun = ephem.Sun(observer)\n",
    "    moon = ephem.Moon(observer)\n",
    "    \n",
    "    sun_alt_deg = math.degrees(sun.alt)\n",
    "    moon_alt_deg = math.degrees(moon.alt)\n",
    "    moon_phase_percent = moon.phase\n",
    "\n",
    "    return sun_alt_deg, moon_alt_deg, moon_phase_percent\n",
    "\n",
    "\n",
    "def filter_by_celestial_conditions(df, observer):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to keep only rows that meet dark sky criteria (sun and moon).\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to filter. Must have a 'Datetime' column.\n",
    "        observer (ephem.Observer): The configured ephem observer.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A filtered DataFrame.\n",
    "    \"\"\"\n",
    "    # Vectorize the calculation for efficiency\n",
    "    altitudes = df.apply(calculate_celestial_altitudes, axis=1, observer=observer, result_type='expand')\n",
    "    df[['sun_alt', 'moon_alt', 'moon_phase']] = altitudes\n",
    "    df.dropna(subset=['sun_alt', 'moon_alt', 'moon_phase'], inplace=True)\n",
    "\n",
    "    # Define the conditions for keeping a row\n",
    "    is_sun_down = df['sun_alt'] < SUN_ALTITUDE_THRESHOLD\n",
    "    \n",
    "    # Moon illumination conditions based on its altitude\n",
    "    cond1 = (df['moon_alt'] >= 0) & (df['moon_alt'] <= 5) & (df['moon_phase'] < (50 - (8 * df['moon_alt'])))\n",
    "    cond2 = (df['moon_alt'] >= -3) & (df['moon_alt'] < 0) & (df['moon_phase'] < ((150 - (50 * df['moon_alt'])) / 3))\n",
    "    cond3 = df['moon_alt'] < -3\n",
    "    \n",
    "    # Keep rows where the sun is down AND any of the moon conditions are met\n",
    "    filtered_df = df[is_sun_down & (cond1 | cond2 | cond3)].copy()\n",
    "    \n",
    "    return filtered_df.drop(columns=['sun_alt', 'moon_alt', 'moon_phase'])\n",
    "\n",
    "\n",
    "def load_and_process_dat_files(folder_path):\n",
    "    \"\"\"\n",
    "    Loads, cleans, combines, and pre-filters all .dat files from a directory.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): The path to the folder containing .dat files.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A single DataFrame with all processed data.\n",
    "    \"\"\"\n",
    "    all_dfs = []\n",
    "    print(f\"Searching for .dat files in: {folder_path}\")\n",
    "    \n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"Error: Directory not found: {folder_path}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".dat\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                df = pd.read_csv(\n",
    "                    file_path,\n",
    "                    delimiter=\";\",\n",
    "                    skiprows=35,\n",
    "                    names=[\"DateTime\", \"DateTime2\", \"Temp\", \"Num\", \"Hz\", \"Magnitude\"],\n",
    "                    on_bad_lines='skip'\n",
    "                )\n",
    "                # Pre-filter files with too few data points\n",
    "                if len(df) < MIN_DATAPOINTS_PER_FILE:\n",
    "                    continue\n",
    "                all_dfs.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not process file {filename}: {e}\")\n",
    "    \n",
    "    if not all_dfs:\n",
    "        print(\"No valid .dat files found after initial filtering.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(f\"Found and loaded {len(all_dfs)} valid .dat files. Processing...\")\n",
    "    \n",
    "    # Combine all data, create a proper datetime object, and filter\n",
    "    full_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    full_df['Datetime'] = pd.to_datetime(full_df['DateTime'], errors='coerce')\n",
    "    full_df.dropna(subset=['Datetime', 'Magnitude'], inplace=True)\n",
    "    full_df = full_df[full_df[\"Magnitude\"] != -0.0]\n",
    "\n",
    "    # Filter for specified hours of the night\n",
    "    full_df = full_df[full_df['Datetime'].dt.hour.isin(HOURS_TO_INCLUDE)]\n",
    "\n",
    "    print(\"Finished processing .dat files.\")\n",
    "    return full_df[['Datetime', 'Magnitude']].copy()\n",
    "\n",
    "\n",
    "def analyze_and_plot_weekly_trend(df, location_name, excluded_cloudy_hours):\n",
    "    \"\"\"\n",
    "    Performs weekly trend analysis on the filtered data and generates a plot.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The pre-filtered data.\n",
    "        location_name (str): The name of the location for the plot title.\n",
    "        excluded_cloudy_hours (set): A set of 'YYYY-MM-DD HH' strings to exclude.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        print(\"No data available for analysis after initial filtering.\")\n",
    "        return\n",
    "\n",
    "    # --- Cloud Filter --- #\n",
    "    # Create a string representation of the hour for filtering\n",
    "    df['datetime_hour_str'] = df['Datetime'].dt.strftime('%Y-%m-%d %H')\n",
    "    df = df[~df['datetime_hour_str'].isin(excluded_cloudy_hours)]\n",
    "    df = df.drop(columns=['datetime_hour_str'])\n",
    "    if df.empty:\n",
    "        print(\"No data remaining after removing cloudy periods.\")\n",
    "        return\n",
    "\n",
    "    # --- Weekly Aggregation --- #\n",
    "    # Convert magnitude to a linear scale for averaging\n",
    "    df['Linear_Magnitude'] = 1.08 * (10**8) * 10**(-0.4 * df['Magnitude'])\n",
    "    df.loc[df['Linear_Magnitude'] > 10, 'Linear_Magnitude'] = np.nan # Remove outliers\n",
    "    df.dropna(subset=['Linear_Magnitude'], inplace=True)\n",
    "    \n",
    "    # Resample to get the median value for each week\n",
    "    weekly_median = df.resample('W', on='Datetime')['Linear_Magnitude'].median()\n",
    "    weekly_median.dropna(inplace=True)\n",
    "\n",
    "    if len(weekly_median) < 2:\n",
    "        print(\"Not enough weekly data points to calculate a trend.\")\n",
    "        return\n",
    "\n",
    "    # --- Regression Analysis --- #\n",
    "    X = np.arange(len(weekly_median)).reshape(-1, 1)\n",
    "    y = weekly_median.values\n",
    "    \n",
    "    reg = LinearRegression().fit(X, y)\n",
    "    trend = reg.predict(X)\n",
    "    \n",
    "    # --- Plotting --- #\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(weekly_median.index, y, 'o', color='darkblue', label='Median Weekly Brightness')\n",
    "    plt.plot(weekly_median.index, trend, linestyle='--', color='red', label='Trend Line')\n",
    "    plt.ylim(0, max(2, y.max() * 1.1))\n",
    "    plt.xticks(fontsize=14, rotation=45)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.xlabel('Time', fontsize=15)\n",
    "    plt.ylabel(r'Median Sky Brightness (mcd/m$^2$)', fontsize=15)\n",
    "    plt.title(f'Weekly Sky Brightness Trend | {location_name}', fontsize=18)\n",
    "    plt.grid(True)\n",
    "    plt.legend(fontsize=15)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- Calculate and Print Statistics --- #\n",
    "    slope_per_sample = reg.coef_[0]\n",
    "    # There are ~52.14 weeks in a year. Slope is per week.\n",
    "    slope_per_year = slope_per_sample * (365.25 / 7)\n",
    "    percentage_change = (slope_per_year / np.median(y)) * 100 if np.median(y) != 0 else 0\n",
    "    \n",
    "    print(\"\\n--- WEEKLY ANALYSIS RESULTS ---\")\n",
    "    print(f\"Trend Slope: {slope_per_year:.4f} mcd/m^2 per year.\")\n",
    "    print(f\"Percentage Change: {percentage_change:.2f}% per year based on weekly medians.\")\n",
    "\n",
    "\n",
    "# ---- MAIN EXECUTION ---- #\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the entire analysis pipeline.\n",
    "    \"\"\"\n",
    "    print(f\"--- Starting Weekly Analysis for: {SELECTED_LOCATION} ---\")\n",
    "    \n",
    "    # 1. Setup Observer\n",
    "    location_coords = LOCATIONS_DICT.get(SELECTED_LOCATION)\n",
    "    if not location_coords:\n",
    "        print(f\"Error: Coordinates for '{SELECTED_LOCATION}' not found in LOCATIONS_DICT.\")\n",
    "        return\n",
    "        \n",
    "    observer = ephem.Observer()\n",
    "    observer.lat = location_coords['lat']\n",
    "    observer.lon = location_coords['lon']\n",
    "\n",
    "    # 2. Load Cloud Data\n",
    "    excluded_cloudy_hours = load_cloud_data(CLOUD_DATA_FILE)\n",
    "\n",
    "    # 3. Load and Process main .dat files\n",
    "    location_data_path = os.path.join(DATA_ROOT_DIR, SELECTED_LOCATION)\n",
    "    df_processed = load_and_process_dat_files(location_data_path)\n",
    "\n",
    "    if df_processed.empty:\n",
    "        print(\"Analysis stopped because no data could be loaded.\")\n",
    "        return\n",
    "    \n",
    "    # 4. Filter by Astronomical Conditions (Sun & Moon)\n",
    "    print(\"Filtering data based on sun and moon positions...\")\n",
    "    df_celestial_filtered = filter_by_celestial_conditions(df_processed, observer)\n",
    "    print(f\"Kept {len(df_celestial_filtered)} rows after celestial filtering.\")\n",
    "\n",
    "    if df_celestial_filtered.empty:\n",
    "        print(\"No data remains after celestial filtering. Cannot proceed.\")\n",
    "        return\n",
    "\n",
    "    # 5. Perform Weekly Analysis and Plotting (Cloud filter is inside this function)\n",
    "    analyze_and_plot_weekly_trend(df_celestial_filtered, SELECTED_LOCATION, excluded_cloudy_hours)\n",
    "        \n",
    "    print(\"\\n--- Analysis Complete ---\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
